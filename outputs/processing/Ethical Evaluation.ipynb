{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter json to only reflect paths with \"Explored\" status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from math import sqrt\n",
    "import os\n",
    "#filename = 'USA_Lanker-2_18_T-1'\n",
    "#data = json.load(open('jsons/astar/' + filename + '.json'))\n",
    "def pos_diff(state_1, state_2):\n",
    "    pos1 = state_1['position']\n",
    "    pos2 = state_2['position']\n",
    "    x_0 = pos1[0]\n",
    "    x_1 = pos2[0]\n",
    "\n",
    "    y_0 = pos1[1]\n",
    "    y_1 = pos2[1]\n",
    "    return sqrt((x_1-x_0)**2 + (y_1-y_0)**2)\n",
    "\n",
    "def filter_by_explored(dataset):\n",
    "    explored = []\n",
    "    for item in dataset.values():\n",
    "        state_list = item[0]\n",
    "        status = item[1]\n",
    "        if status == \"MotionPrimitiveStatus.EXPLORED\":\n",
    "            explored.append(state_list)\n",
    "    return explored\n",
    "\n",
    "def find_max_node(dataset):\n",
    "    max_ts = 0\n",
    "    for path in dataset:\n",
    "        if (path[-1]['time_step'] > max_ts):\n",
    "            max_ts = path[-1]['time_step']\n",
    "    return max_ts\n",
    "\n",
    "def find_path(dataset, node, to_test_next, paths):\n",
    "    if node[0]['time_step'] == 0:\n",
    "        if node not in paths:\n",
    "            paths.append(node)\n",
    "    else:\n",
    "        for path in dataset:\n",
    "            if path[-1]['time_step'] == node[0]['time_step'] and pos_diff(path[-1], node[0]) == 0:\n",
    "                new_node = path[:-1] + node\n",
    "                find_path(dataset, new_node, to_test_next, paths)\n",
    "            if path[-1]['time_step'] == node[0]['time_step'] and pos_diff(path[-1], node[0]) > 0:\n",
    "                if path not in to_test_next:\n",
    "                    to_test_next.append(path)\n",
    "\n",
    "def find_all_paths(dataset, paths):\n",
    "    max_ts = find_max_node(dataset)\n",
    "    to_test_next = []\n",
    "    for path in dataset:\n",
    "        if path[-1]['time_step'] == max_ts:\n",
    "            to_test_next.append(path)\n",
    "    while (len(to_test_next) > 0):\n",
    "        to_test = to_test_next[0]\n",
    "        to_test_next.remove(to_test)\n",
    "        find_path(dataset, to_test, to_test_next, paths)\n",
    "    return paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy over long_dist, lane_track, relative_speed, and ke_transfer metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "from commonroad.geometry.shape import Rectangle\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "def distance(x_0, x_1, y_0, y_1):\n",
    "    return sqrt((x_1-x_0)**2 + (y_1-y_0)**2)\n",
    "\n",
    "def get_shortest_distance(vert_1, vert_2):\n",
    "    \n",
    "    X = vert_1\n",
    "    Y = vert_2\n",
    "\n",
    "    # maximum thickness separating slab\n",
    "    a, b = cp.Variable(2), cp.Variable()\n",
    "    prob = cp.Problem(cp.Minimize(cp.norm2(a)), [a.T@X - b >= 1, a.T@Y - b <= -1])\n",
    "    prob.solve()\n",
    "    if a.value is None:\n",
    "        return 0\n",
    "    width_max = 2 / np.linalg.norm(a.value)\n",
    "    return width_max\n",
    "\n",
    "\n",
    "def create_tvobstacle(traj_list,car_half_length,car_half_width, i):\n",
    "    tvo=pycrcc.TimeVariantCollisionObject(i)\n",
    "    for traj in traj_list:\n",
    "        orien = 0\n",
    "        try:\n",
    "            orien = traj.shape.orientation\n",
    "        except AttributeError:\n",
    "            print('not rectangle')\n",
    "        tvo.append_obstacle(pycrcc.RectOBB(car_half_length, car_half_width, orien,traj.shape.center[0],traj.shape.center[1]))\n",
    "    return tvo\n",
    "def create_new_ego_tvo(rect_list, i):\n",
    "    tvo=pycrcc.TimeVariantCollisionObject(i)\n",
    "    for i in range(i, len(rect_list)):\n",
    "        rect = rect_list[i]\n",
    "        half_length = rect.length/2\n",
    "        half_width = rect.width/2\n",
    "        orientation = rect.orientation\n",
    "        pos_x = rect.center[0]\n",
    "        pos_y = rect.center[1]\n",
    "        \n",
    "        tvo.append_obstacle(pycrcc.RectOBB(half_length, half_width, orientation, pos_x, pos_y))\n",
    "        \n",
    "    return tvo\n",
    "        \n",
    "\n",
    "\n",
    "def long_dist(scenario):\n",
    "    \n",
    "    violations = []\n",
    "    tvo=pycrcc.TimeVariantCollisionObject(0)\n",
    "    all_ego_rects = []\n",
    "    obs_obj_dict = {}\n",
    "    safe_dist_list = []\n",
    "    \n",
    "    \n",
    "    ego = scenario.obstacle_by_id(-1)\n",
    "    max_len = len(ego.prediction.trajectory.state_list)\n",
    "    car_length = ego.obstacle_shape.length\n",
    "    car_width = ego.obstacle_shape.width\n",
    "    \n",
    "    state_list = ego.prediction.trajectory.state_list\n",
    "    \n",
    "    for obs in scenario.dynamic_obstacles:\n",
    "        length = obs.obstacle_shape.length\n",
    "        width = obs.obstacle_shape.width\n",
    "        tvo = create_tvobstacle(obs.prediction.occupancy_set, length/2, width/2, 0)\n",
    "        obs_obj_dict[tvo] = obs\n",
    "    \n",
    "    for i in range(0, len(state_list)-1):\n",
    "        violations.append(0)\n",
    "        current_pos = state_list[i].position\n",
    "        next_pos = state_list[i+1].position\n",
    "        orientation = state_list[i].orientation\n",
    "        \n",
    "        x = current_pos[0]\n",
    "        y = current_pos[1]\n",
    "        x_1 = next_pos[0]\n",
    "        y_1 = next_pos[1]\n",
    "        \n",
    "        v = distance(x, x_1, y, y_1)\n",
    "        safe_dist = 3*v\n",
    "        center = np.array([x, y])\n",
    "        length = car_length\n",
    "        safe_dist_list.append(safe_dist)\n",
    "\n",
    "        if (v > 0):\n",
    "            length = car_length + safe_dist\n",
    "            offset_magnitude = length - (car_length)\n",
    "            offset_x = ((x_1-x)/v)*(offset_magnitude)\n",
    "            offset_y = ((y_1-y)/v)*(offset_magnitude)\n",
    "            center = np.array([x+offset_x, y+offset_y])\n",
    "        \n",
    "        ego_rect = Rectangle(length,car_width,center,orientation)\n",
    "        all_ego_rects.append(ego_rect)\n",
    "        \n",
    "        tvo.append_obstacle(pycrcc.RectOBB(length/2, car_width/2, orientation,center[0],center[1]))\n",
    "    done = False\n",
    "    while not done:\n",
    "        collision_found = False\n",
    "        for co in obs_obj_dict.keys():\n",
    "            t = trajectories_collision_dynamic_obstacles([tvo], [co])[0]\n",
    "            if t == 0 and len(all_ego_rects) == 0:\n",
    "                done = True\n",
    "            if t != -1:\n",
    "                collision_found = True\n",
    "                \n",
    "                if (t < len(all_ego_rects)):\n",
    "                    ego_safe_rect = np.transpose(all_ego_rects[t].vertices[:-1])\n",
    "                    ego_actual_rect = np.transpose(ego.prediction.occupancy_at_time_step(t).shape.vertices[:-1])\n",
    "\n",
    "                    obs_vertices = np.transpose(obs_obj_dict[co].prediction.occupancy_at_time_step(t).shape.vertices[:-1])\n",
    "\n",
    "\n",
    "\n",
    "                    safe_dist = get_shortest_distance(ego_safe_rect, obs_vertices)\n",
    "                    if safe_dist == 0:\n",
    "                        actual_dist = get_shortest_distance(ego_actual_rect, obs_vertices)\n",
    "                        threshold = safe_dist_list[t]\n",
    "                        violation = threshold - actual_dist\n",
    "                        if violation < 0:\n",
    "                            violation = 0\n",
    "                        violations[t] = violation\n",
    "\n",
    "                    tvo = create_new_ego_tvo(all_ego_rects, t+1)\n",
    "        if collision_found == False:\n",
    "            done = True\n",
    "                \n",
    "                \n",
    "                \n",
    "        \n",
    "    return violations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lane_tracking(scenario):\n",
    "    \n",
    "    ego = scenario.obstacle_by_id(-1)\n",
    "    state_list = ego.prediction.trajectory.state_list\n",
    "    \n",
    "    desired_state_list = []\n",
    "    error_list = []\n",
    "    for i in range(0, len(state_list)-1):\n",
    "        desired_state_list.append(state_list[i].position)\n",
    "        error_list.append(1000000.0)\n",
    "    for i in range(0, len(state_list)-1):\n",
    "        candidate_lanelets = []\n",
    "        for lanelet in scenario.lanelet_network.lanelets:\n",
    "            pos = state_list[i].position\n",
    "            if (lanelet.convert_to_polygon().contains_point(pos)):\n",
    "                candidate_lanelets.append(lanelet)\n",
    "        for lanelet in candidate_lanelets:\n",
    "            \n",
    "            lanelet_start = lanelet.interpolate_position(0)[0]\n",
    "            curr_pos = state_list[i].position\n",
    "            init_dist = distance(lanelet_start[0], curr_pos[0], lanelet_start[1], curr_pos[1])\n",
    "            \n",
    "            next_pos = state_list[i+1].position\n",
    "            next_dist = distance(next_pos[0], curr_pos[0], next_pos[1], curr_pos[1])\n",
    "            \n",
    "            if(init_dist + next_dist <= lanelet.distance[-1]):\n",
    "                desired_pos = lanelet.interpolate_position(init_dist + next_dist)[0]\n",
    "                error = distance(desired_pos[0], next_pos[0], desired_pos[1], next_pos[1])\n",
    "            \n",
    "                if (error < error_list[i]):\n",
    "                    desired_state_list[i] = desired_pos\n",
    "                    \n",
    "                    error_list[i] = error\n",
    "            else: \n",
    "                #edge case where we have reached the end of a lanelet and cannot calculate interpolated position\n",
    "                desired_pos = lanelet.interpolate_position(lanelet.distance[-1])[0]\n",
    "                error = distance(desired_pos[0], next_pos[0], desired_pos[1], next_pos[1])\n",
    "            \n",
    "                if (error < error_list[i]):\n",
    "                    desired_state_list[i] = desired_pos\n",
    "                    error_list[i] = error\n",
    "    return error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_speed(scenario):    \n",
    "    avg_v = []\n",
    "    differential_v = []\n",
    "    \n",
    "    ego = scenario.obstacle_by_id(-1)\n",
    "    state_list = ego.prediction.trajectory.state_list\n",
    "    count = len(scenario.dynamic_obstacles)\n",
    "    for i in range(0, len(state_list)-1):\n",
    "        total_v = 0\n",
    "        for obs in scenario.dynamic_obstacles:\n",
    "            if obs.obstacle_id != -1:\n",
    "                if obs.prediction.occupancy_at_time_step(i+1) is not None and obs.prediction.occupancy_at_time_step(i) is not None:\n",
    "                    pos_1 = obs.prediction.occupancy_at_time_step(i).shape.center\n",
    "                    pos_2 = obs.prediction.occupancy_at_time_step(i+1).shape.center\n",
    "                    obs_v = distance(pos_1[0], pos_2[0], pos_1[1], pos_2[1])\n",
    "                    total_v = total_v + obs_v\n",
    "        avg_v.append(total_v/count)\n",
    "        ego_pos_1 = ego.prediction.occupancy_at_time_step(i).shape.center\n",
    "        ego_pos_2 = ego.prediction.occupancy_at_time_step(i+1).shape.center\n",
    "        ego_v = distance(ego_pos_1[0], ego_pos_2[0], ego_pos_1[1], ego_pos_2[1])\n",
    "        diff_v = ego_v - (total_v/count)\n",
    "        differential_v.append(diff_v)\n",
    "    return differential_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from commonroad_dc.collision.trajectory_queries.trajectory_queries import trajectories_collision_dynamic_obstacles\n",
    "from commonroad_dc import pycrcc\n",
    "import cvxpy as cp\n",
    "\n",
    "def get_shortest_distance_ke(obs_1, obs_2, i):\n",
    "    \n",
    "    X = np.transpose(obs_1.occupancy_at_time(i).shape.vertices[:-1])\n",
    "    Y = np.transpose(obs_2.occupancy_at_time(i).shape.vertices[:-1])\n",
    "\n",
    "    # maximum thickness separating slab\n",
    "    a, b = cp.Variable(2), cp.Variable()\n",
    "    prob = cp.Problem(cp.Minimize(cp.norm2(a)), [a.T@X - b >= 1, a.T@Y - b <= -1])\n",
    "    prob.solve()\n",
    "    if a.value is None:\n",
    "        return 0\n",
    "    width_max = 2 / np.linalg.norm(a.value)\n",
    "    return width_max\n",
    "\n",
    "def create_tvobstacle(traj_list,car_half_length,car_half_width, i):\n",
    "    tvo=pycrcc.TimeVariantCollisionObject(i)\n",
    "    for traj in traj_list:\n",
    "        orien = 0\n",
    "        try:\n",
    "            orien = traj.shape.orientation\n",
    "        except AttributeError:\n",
    "            orien = 0\n",
    "        tvo.append_obstacle(pycrcc.RectOBB(car_half_length, car_half_width, orien,traj.shape.center[0],traj.shape.center[1]))\n",
    "    return tvo\n",
    "\n",
    "\n",
    "def ke_transfer(scenario):\n",
    "    ego = scenario.obstacle_by_id(-1)\n",
    "    pred = ego.prediction.occupancy_set\n",
    "    traj = ego.prediction.trajectory.state_list\n",
    "    length = 2.15\n",
    "    width = 0.9\n",
    "    co_dict = {}\n",
    "    for obs in scenario.dynamic_obstacles:\n",
    "        state_list = obs.prediction.occupancy_set\n",
    "        obs_tvo = create_tvobstacle(state_list, length, width, 0)\n",
    "        co_dict[obs_tvo] = obs\n",
    "    co_list = list(co_dict.keys())\n",
    "    ke_transfer_vals = []\n",
    "    for i in range(0, len(traj)):\n",
    "        ke_transfer_vals.append(0)\n",
    "    tvo = create_tvobstacle(pred, length, width, 0)\n",
    "    collision_found = False\n",
    "    while (not collision_found):\n",
    "        for tvo_obs in co_list:\n",
    "            t = trajectories_collision_dynamic_obstacles([tvo], [tvo_obs])[0]\n",
    "            #if t == -1:\n",
    "                #return ke_transfer_vals\n",
    "            if t>0:\n",
    "                obs = co_dict[tvo_obs]\n",
    "                if get_shortest_distance_ke(ego, obs, t) == 0:\n",
    "                    collision_found = True\n",
    "                    \n",
    "                    ke = 0.5*1500*(traj[t].velocity**2)\n",
    "                    \n",
    "                    ke_transfer_vals[t] = ke\n",
    "        tvo = create_tvobstacle(pred[t+1:], length, width, t+1)\n",
    "    return ke_transfer_vals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert explored paths to trajectories to append to scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "from commonroad.scenario.trajectory import State\n",
    "\n",
    "def convert_to_traj(state_list):\n",
    "    new_state_list = []\n",
    "    \n",
    "    for state in state_list:\n",
    "        pos = np.array(state['position'])\n",
    "        orien = state['orientation']\n",
    "        vel = state['velocity']\n",
    "        ts = state['time_step']\n",
    "        \n",
    "        new_state = State(position=pos, orientation=orien, velocity=vel, time_step=ts)\n",
    "        \n",
    "        new_state_list.append(new_state)\n",
    "    return new_state_list\n",
    "\n",
    "def process_paths(paths, scenario_id):\n",
    "    scenario, _ = CommonRoadFileReader('../commonroad-scenarios-master/' + scenario_id + '.xml').open()\n",
    "    max_ts = 0\n",
    "    new_paths = []\n",
    "    for obs in scenario.dynamic_obstacles:\n",
    "        if len(obs.prediction.occupancy_set) > max_ts:\n",
    "            max_ts = len(obs.prediction.occupancy_set)\n",
    "    for i in range(0, len(paths)):\n",
    "        path = paths[i]\n",
    "        new_path = path[0:min(max_ts, len(path))]\n",
    "        if new_path not in new_paths and len(new_path) > 0:\n",
    "            new_paths.append(new_path)\n",
    "    return new_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions determining adherence to ethical framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#input df in form of file, safety sum, ke_transfer\n",
    "def is_consequentialist(df):\n",
    "    df['ke_transfer_rank'] = df['ke_transfer'].rank()\n",
    "    df = df.sort_values(by=['ke_transfer_rank'])\n",
    "    min_rank = df['ke_transfer_rank'].min()\n",
    "    if df.iloc[0]['ke_transfer_rank'] == min_rank:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "#input df in form of file, safety sum, ke_transfer\n",
    "def is_utilitarian(df):\n",
    "    df['ke_safety_sum'] = df['safety_sum'] + df['ke_transfer']\n",
    "    df['ke_safety_sum_rank'] = df['ke_safety_sum'].rank()\n",
    "    min_rank = df['ke_safety_sum_rank'].min()\n",
    "    if df.iloc[0]['ke_safety_sum_rank'] == min_rank:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    \n",
    "#input df in form of file, metric, and each time step\n",
    "def is_deontological(df, chosen_traj):\n",
    "    new_df = df[df[0] == chosen_traj]\n",
    "    ke = new_df[new_df[1] == 'ke_transfer']\n",
    "    s = ke.iloc[0, 2:].astype('float64')\n",
    "    ts = 0\n",
    "    try:\n",
    "        ts = s.loc[s>0].index[0] - 1\n",
    "    except IndexError as e:\n",
    "        return True\n",
    "    long_dist = new_df[new_df[1] == 'long_dist'].iloc[0:, ts].reset_index(drop=True)[0]\n",
    "    lane_track = new_df[new_df[1] == 'lane_track'].iloc[0:, ts].reset_index(drop=True)[0]\n",
    "    relative_speed = new_df[new_df[1] == 'relative_speed'].iloc[0:, ts].reset_index(drop=True)[0]\n",
    "    if long_dist == 0 and lane_track == 0 and relative_speed == 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def create_combined_df(df_planner):\n",
    "\n",
    "    planner_list = []\n",
    "    for filename in df_planner[0].unique():\n",
    "        new_df = df_planner[df_planner[0] == filename]\n",
    "        long_dist = pd.to_numeric(new_df[new_df[1] == 'long_dist'].iloc[0, 2:])\n",
    "        lane_track = abs(pd.to_numeric(new_df[new_df[1] == 'lane_track'].iloc[0, 2:]))\n",
    "        relative_speed = abs(pd.to_numeric(new_df[new_df[1] == 'relative_speed'].iloc[0, 2:]))\n",
    "        kinetic_energy = pd.to_numeric(new_df[new_df[1] == 'ke_transfer'].iloc[0, 2:])\n",
    "\n",
    "        num = np.where(np.isnan(np.array(long_dist)))[0][0]\n",
    "\n",
    "        long_dist_sum = np.nansum(long_dist)\n",
    "        lane_track_sum = np.nansum(lane_track)\n",
    "        relative_speed_sum = np.nansum(relative_speed)\n",
    "\n",
    "        total_sum = long_dist_sum + lane_track_sum + relative_speed_sum\n",
    "        avg = total_sum/num\n",
    "\n",
    "        ke_sum = np.nansum(kinetic_energy)\n",
    "\n",
    "        file_list = [filename, avg, ke_sum]\n",
    "        planner_list.append(file_list)\n",
    "    df_planner_combined = pd.DataFrame(planner_list, columns = ['file', 'safety_sum', 'ke_transfer'])\n",
    "\n",
    "    return df_planner_combined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If scenario has a solution, append that solution to all of the paths explored. Then, generate metrics for each path in final list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from commonroad.common.file_reader import CommonRoadFileReader\n",
    "from commonroad.scenario.obstacle import DynamicObstacle\n",
    "from commonroad.scenario.trajectory import Trajectory\n",
    "from commonroad.prediction.prediction import TrajectoryPrediction\n",
    "from commonroad.scenario.obstacle import ObstacleType\n",
    "\n",
    "\n",
    "def append_solution(path, filename, paths_explored):\n",
    "    try:\n",
    "        scenario, _ = CommonRoadFileReader(path).open()\n",
    "    except FileNotFoundError as e:\n",
    "        return paths_explored\n",
    "    solution = scenario.obstacle_by_id(-1).prediction.trajectory.state_list\n",
    "    if len(solution) > 0:\n",
    "        paths = [scenario.obstacle_by_id(-1).prediction.trajectory.state_list] + paths_explored\n",
    "        return paths\n",
    "    else:\n",
    "        return paths_explored\n",
    "\n",
    "# add dynamic obstacle to the scenario\n",
    "def get_metrics_all_paths(paths, scenario_id):\n",
    "    df_list = []\n",
    "    \n",
    "    \n",
    "    for traj in paths:\n",
    "        count = 0\n",
    "        scenario, _ = CommonRoadFileReader('../commonroad-scenarios-master/' + scenario_id + '.xml').open()\n",
    "        \n",
    "        dynamic_obstacle_trajectory = Trajectory(1, traj)\n",
    "\n",
    "        # create the prediction using the trajectory and the shape of the obstacle\n",
    "        dynamic_obstacle_shape = Rectangle(width = 1.8, length = 4.3)\n",
    "        dynamic_obstacle_prediction = TrajectoryPrediction(dynamic_obstacle_trajectory, dynamic_obstacle_shape)\n",
    "\n",
    "        # generate the dynamic obstacle according to the specification\n",
    "        dynamic_obstacle_id = -1\n",
    "        dynamic_obstacle_type = ObstacleType.CAR\n",
    "        dynamic_obstacle = DynamicObstacle(dynamic_obstacle_id, \n",
    "                                           dynamic_obstacle_type, \n",
    "                                           dynamic_obstacle_shape, \n",
    "                                           traj[0], \n",
    "                                           dynamic_obstacle_prediction)\n",
    "        scenario.add_objects(dynamic_obstacle)\n",
    "        \n",
    "        scenario_count = 'scenario_' + str(count)\n",
    "        long_dist_list = long_dist(scenario)\n",
    "        lane_tracking_list = lane_tracking(scenario)\n",
    "        relative_speed_list = relative_speed(scenario)\n",
    "        ke_transfer_list = ke_transfer(scenario)\n",
    "        \n",
    "        ld = pd.Series([scenario_count, 'long_dist'] + long_dist_list)\n",
    "        lt = pd.Series([scenario_count, 'lane_track'] + lane_tracking_list)\n",
    "        rs = pd.Series([scenario_count, 'relative_speed'] + relative_speed_list)\n",
    "        ke = pd.Series([scenario_count, 'ke_transfer'] + ke_transfer_list)\n",
    "        \n",
    "        df_list.append(ld)\n",
    "        df_list.append(lt)\n",
    "        df_list.append(rs)\n",
    "        df_list.append(ke)\n",
    "    df = pd.DataFrame(df_list)\n",
    "    combined_df = create_combined_df(df)\n",
    "    return df, combined_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run process_jsons with valid args (json_path: path to json files to read from; csv_path: path to output dataframe to) on multiple jsons in a directory to determine if scenario is safe and ethical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from multiprocessing import Process, Manager\n",
    "\n",
    "def process_dfs(paths_with_solution, file, num_paths, contains_solution, writer, row):\n",
    "    \n",
    "    cons = False\n",
    "    util = False\n",
    "    deon = False\n",
    "    try:\n",
    "\n",
    "        df, combined_df = get_metrics_all_paths(paths_with_solution, file[:-5])\n",
    "        print('done generating dfs')\n",
    "\n",
    "        cons = is_consequentialist(combined_df)\n",
    "        util = is_utilitarian(combined_df)\n",
    "        deon = is_deontological(df, 'scenario_0')\n",
    "    except AttributeError:\n",
    "        print('here')\n",
    "        cons = False\n",
    "        util = False\n",
    "        deon = False\n",
    "\n",
    "    row.append(file[:-5]) #[file[:-5], contains_solution, num_paths, cons, util, deon]\n",
    "    row.append(contains_solution)\n",
    "    row.append(num_paths)\n",
    "    row.append(cons)\n",
    "    row.append(util)\n",
    "    row.append(deon)\n",
    "\n",
    "    \n",
    "def process_jsons(json_path, csv_path):\n",
    "    with open(csv_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "        for file in os.listdir(json_path):\n",
    "            if not file.startswith('.') and os.path.isfile(os.path.join(json_path, file)):\n",
    "                contains_solution = False\n",
    "                num_paths = 0\n",
    "\n",
    "\n",
    "                data = json.load(open(json_path + file))\n",
    "                explored = filter_by_explored(data)\n",
    "                \n",
    "                \n",
    "                manager = Manager()\n",
    "                final_paths = manager.list()\n",
    "                p = Process(target=find_all_paths, args=(explored, final_paths))\n",
    "                #all_paths = find_all_paths(explored, final_paths)\n",
    "                p.start()\n",
    "                p.join(timeout=120)\n",
    "                all_paths_truncated = []\n",
    "                try:\n",
    "                    all_paths_truncated = process_paths(final_paths, file[:-5])\n",
    "                except (AttributeError, FileNotFoundError):\n",
    "                    all_paths_truncated = final_paths\n",
    "                all_trajs = []\n",
    "                if len(all_paths_truncated) > 0:\n",
    "                    for p in all_paths_truncated:\n",
    "                        traj = convert_to_traj(p)\n",
    "                        all_trajs.append(traj)\n",
    "                        \n",
    "                solved_scenario_path = '../solved_scenarios/' + file[:-5]\n",
    "                paths_with_solution = append_solution(solved_scenario_path, file[:-5], all_trajs)\n",
    "                num_paths = len(paths_with_solution)\n",
    "                if num_paths > len(all_trajs):\n",
    "                    contains_solution = True\n",
    "                if num_paths == 0:\n",
    "                    row = [file[:-5], False, 0, False, False, False]\n",
    "                    print(row)\n",
    "                    writer.writerow(row)\n",
    "\n",
    "                else:\n",
    "                    manager = Manager()\n",
    "                    row = manager.list()\n",
    "                    p = Process(target=process_dfs, args=(paths_with_solution, file, num_paths, contains_solution, writer, row))\n",
    "                    p.start()\n",
    "                    p.join(timeout=120)\n",
    "                    print(row)\n",
    "                    writer.writerow(row)\n",
    "                    # if TIMEOUT\n",
    "                    if p.is_alive():\n",
    "                        p.terminate()\n",
    "                        print('timeout')\n",
    "                        writer.writerow([file[:-5], contains_solution, num_paths, False, False, False])\n",
    "                    \n",
    "\n",
    "                print('done with file ' + file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
